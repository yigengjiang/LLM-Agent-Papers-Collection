# LLM-Agent-Papers-Collection
A collection of **papers** on Large Language Model Agents

Our collection of papers focuses on various aspects of ***LLM-Agent Design Patterns***. The design patterns can be abstracted and illustrated as shown in the figure below. The collection is categorized into actions, memory, reasoning, agents, and multi-agent collaboration.

![agent_design_pattern](assets/agent_design_pattern.png)

Besides the aspects shown in the figure, this repository will also include: overview of LLM-Agent, benchmarks, prompt design.

# Agent Design Patterns

## Actions

1. [Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries](https://arxiv.org/abs/2407.21778) 2024.7
1. [Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM Agents](https://openreview.net/pdf?id=MGkeWJxQVl) ICML2024
1. [Multi-Programming Language Sandbox for LLMs](https://arxiv.org/pdf/2410.23074) 2024.10

## Memory

1. [360° REA: Towards A Reusable Experience Accumulation with Assessment for Multi-Agent System](https://arxiv.org/abs/2404.05569) ACL2024
1. [Symbolic Working Memory Enhances Language Models for Complex Rule Application](https://arxiv.org/abs/2408.13654) 2024.8
1. [MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery](https://arxiv.org/abs/2409.05591) 2024.9
1. [AGENT WORKFLOW MEMORY](https://arxiv.org/pdf/2409.07429) 2024.9

## Reasoning

1. [ AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation](https://arxiv.org/abs/2408.00764) 2024.8
1. [Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks](https://arxiv.org/pdf/2408.03615) 2024.8
1. [Position: LLMs Can’t Plan, But Can Help Planning in LLM-Modulo Frameworks](https://arxiv.org/pdf/2402.01817) ICML2024
1. [Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?](https://arxiv.org/abs/2402.18272) ACL2024
1. [Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation](https://arxiv.org/abs/2409.03271) 2024.9
1. [Self-Harmonized Chain of Thought](https://arxiv.org/abs/2409.04057) 2024.9
1. [Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning](https://arxiv.org/abs/2409.12618) 2024.9
1. [Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation](https://arxiv.org/pdf/2409.12411) 2024.9
1. [Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models](https://arxiv.org/abs/2409.17539) 2024.9
1. [BEATS: OPTIMIZING LLM MATHEMATICAL CAPABILITIES WITH BACKVERIFY AND ADAPTIVE DISAMBIGUATE BASED EFFICIENT TREE SEARCH](https://arxiv.org/pdf/2409.17972) 2024.9
1. [HDFLOW: ENHANCING LLM COMPLEX PROBLEMSOLVING WITH HYBRID THINKING AND DYNAMIC WORKFLOWS](https://arxiv.org/pdf/2409.17433) 2024.9
1. [CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning](https://arxiv.org/abs/2410.10336) 2024.10
1. [Optimizing Chain-of-Thought Reasoning: Tackling Arranging Bottleneck via Plan Augmentation](https://arxiv.org/abs/2410.16812) 2024.10
1. [Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph](https://arxiv.org/abs/2411.19064) 2024.12 KDD2025
1. [MTMT: Consolidating Multiple Thinking Modes to Form a Thought Tree for Strengthening LLM](https://arxiv.org/pdf/2412.03987) 2024.12
1. [THINK-ON-GRAPH: DEEP AND RESPONSIBLE REASONING OF LARGE LANGUAGE MODEL ON KNOWLEDGE GRAPH](https://arxiv.org/pdf/2307.07697) ICLR 2024
1. [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](https://arxiv.org/abs/2403.06932) 2024.3 ACL2024

## Agent

1. [From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future](https://arxiv.org/abs/2408.02479) 2024.8
2. [MathLearner: A Large Language Model Agent Framework for Learning to Solve Mathematical Problems](https://arxiv.org/abs/2408.01779) 2024.8
3. [Executable Code Actions Elicit Better LLM Agents](https://arxiv.org/pdf/2402.01030) ICML2024
4. [Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents](https://arxiv.org/pdf/2408.07199) 2024.8
5. [SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning](https://arxiv.org/abs/2409.05556) 2024.9



## Multi-agent Collaboration

1. [Experiential Co-Learning](https://arxiv.org/abs/2312.17025) ACL2024
1. [Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs](https://openreview.net/forum?id=CrUmgUaAQp) ICML2024
1. [Improving Factuality and Reasoning in Language Models through Multiagent Debate](https://arxiv.org/pdf/2305.14325) ICML2024
1. [Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models](https://arxiv.org/abs/2409.13753)

# Additional Topics Covered

## Overview of LLM-Agent

## Benchmarks

1. [OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems.](https://github.com/OpenBMB/OlympiadBench) ACL2024

1. [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](https://arxiv.org/abs/2408.01122) 2024.8

1. [Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information](https://arxiv.org/abs/2408.02559) 2024.8

1. [TravelPlanner: A Benchmark for Real-World Planning with Language Agents](https://arxiv.org/pdf/2402.01622) ICML 2024

1. [LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench](https://arxiv.org/abs/2409.13373) 2024.9

1. [Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models](https://arxiv.org/abs/2410.07985) 2024.10

   



## Prompt Design

1. [Minstrel: Structural Prompt Generation with Multi-Agents
   Coordination for Non-AI Experts](https://arxiv.org/pdf/2409.13449) 2024.9

# Continuous Updates

This repository will be continuously updated as new research on LLM Agents is conducted. Stay tuned for the latest papers, benchmarks, and innovations in the field.
